"""
The many-to-one attention is the same as the weighted-sequence attention
(tha latter seems not so correct, so just use the many-to-one-attention)
"""